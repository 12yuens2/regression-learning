{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EnergySet = pd.read_csv(\"data/energydata_complete.csv\")\n",
    "energydf = pd.DataFrame(data=EnergySet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick look at what the dataset contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "energydf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split training and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training and test data\n",
    "energy_train, energy_test = train_test_split(energydf, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Cleaning the data and converting any data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For showing off our preprocessing steps, a copy of the training data is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_set = energy_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# See if there are incorrect values from mix/max\n",
    "# eg, negative humidity\n",
    "pd.set_option(\"display.max_columns\", 30)\n",
    "preprocessing_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data\n",
    "Clean data for invalid values like negative humidity or unrealistic temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(min_value, max_value, columns, data):\n",
    "    clean_data = data.copy()\n",
    "    for col in columns:\n",
    "        # Only keep rows where column date is within the min and max values\n",
    "        clean_data = clean_data[ (clean_data[col] <= max_value)\n",
    "                               & (clean_data[col] >= min_value)]\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of using the `clean_data` method, where we want the column `T1` to have values between 20 and 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data(20,50,[\"T1\"],preprocessing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisation\n",
    "Plot visualisations of data to see if we can gain any insight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = preprocessing_set.hist(bins=100,figsize=(20,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation between each temperature/humidity reading as they on the same sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ts = [\"T1\", \"T2\", \"T3\", \"T4\", \"T5\", \"T6\", \"T7\", \"T8\", \"T9\", \"T_out\"]\n",
    "RHs = [\"RH_1\", \"RH_2\", \"RH_3\", \"RH_4\", \"RH_5\", \"RH_6\", \"RH_7\", \"RH_8\", \"RH_9\", \"RH_out\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,12))\n",
    "fig.subplots_adjust(wspace=0.5)\n",
    "for i in range(len(Ts)):\n",
    "    plt.subplot(3,4,(i+1))\n",
    "    plt.scatter(preprocessing_set[Ts[i]], preprocessing_set[RHs[i]], alpha=0.02)\n",
    "    plt.xlabel(Ts[i])\n",
    "    plt.ylabel(RHs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert date timestamp to numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def parse_timestamp(timestamp):\n",
    "    return datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A testing dataframe is populated here to show examples of each conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_test = preprocessing_set.copy()\n",
    "time_test = time_test.loc[:, \"date\":\"Appliances\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric\n",
    "Turn datetime into basic numeric forms, for example monday=0, tuesday=1..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numeric_time(timestamp):\n",
    "    dt = parse_timestamp(timestamp)\n",
    "    hour = dt.hour\n",
    "    day = dt.weekday()\n",
    "    \n",
    "    return hour,day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example numeric time conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_test[[\"hour_num\", \"day_num\"]] = preprocessing_set[\"date\"].map(get_numeric_time).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour_num</th>\n",
       "      <th>day_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11928</th>\n",
       "      <td>2016-04-03 13:00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11089</th>\n",
       "      <td>2016-03-28 17:10:00</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8623</th>\n",
       "      <td>2016-03-11 14:10:00</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15433</th>\n",
       "      <td>2016-04-27 21:10:00</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11827</th>\n",
       "      <td>2016-04-02 20:10:00</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date  hour_num  day_num\n",
       "11928  2016-04-03 13:00:00        13        6\n",
       "11089  2016-03-28 17:10:00        17        0\n",
       "8623   2016-03-11 14:10:00        14        4\n",
       "15433  2016-04-27 21:10:00        21        2\n",
       "11827  2016-04-02 20:10:00        20        5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_test[[\"date\",\"hour_num\", \"day_num\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cyclic\n",
    "Due to the nature of time being cyclical, we want to keep this characteristic for our learning model. A way to do this is using sine and cosine transformations.\n",
    "https://ianlondon.github.io/blog/encoding-cyclical-features-24hour-time/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cyclic_time(timestamp):\n",
    "    dt = parse_timestamp(timestamp)\n",
    "    \n",
    "    hour_sin = np.sin(2*np.pi*dt.hour/24)\n",
    "    hour_cos = np.cos(2*np.pi*dt.hour/24)\n",
    "    day_sin = np.sin(2*np.pi*dt.weekday()/7)\n",
    "    day_cos = np.cos(2*np.pi*dt.weekday()/7)\n",
    "    \n",
    "    return hour_sin, hour_cos, day_sin, day_cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example cyclic time conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_test[[\"hour_sin\", \"hour_cos\", \"day_sin\", \"day_cos\"]] = preprocessing_set[\"date\"].map(get_cyclic_time).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11928</th>\n",
       "      <td>2016-04-03 13:00:00</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11089</th>\n",
       "      <td>2016-03-28 17:10:00</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8623</th>\n",
       "      <td>2016-03-11 14:10:00</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15433</th>\n",
       "      <td>2016-04-27 21:10:00</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11827</th>\n",
       "      <td>2016-04-02 20:10:00</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date  hour_sin  hour_cos   day_sin   day_cos\n",
       "11928  2016-04-03 13:00:00 -0.258819 -0.965926 -0.781831  0.623490\n",
       "11089  2016-03-28 17:10:00 -0.965926 -0.258819  0.000000  1.000000\n",
       "8623   2016-03-11 14:10:00 -0.500000 -0.866025 -0.433884 -0.900969\n",
       "15433  2016-04-27 21:10:00 -0.707107  0.707107  0.974928 -0.222521\n",
       "11827  2016-04-02 20:10:00 -0.866025  0.500000 -0.974928 -0.222521"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_test[[\"date\", \"hour_sin\", \"hour_cos\", \"day_sin\", \"day_cos\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seconds from midnight\n",
    "A feature used by the paper is to extract the timestamp as the number of seconds from midnight (NSM) instead of using the actual hours of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nsm(timestamp):\n",
    "    dt = parse_timestamp(timestamp)\n",
    "    midnight = dt.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    \n",
    "    seconds = (dt - midnight).seconds\n",
    "    \n",
    "    return seconds\n",
    "    \n",
    "def get_cyclic_nsm(timestamp):\n",
    "    seconds = get_nsm(timestamp)\n",
    "    seconds_sin = np.sin(2*np.pi*seconds/(24*60*60))\n",
    "    seconds_cos = np.cos(2*np.pi*seconds/(24*60*60))\n",
    "    \n",
    "    return seconds_sin, seconds_cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example NSM conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_test[[\"NSM\"]] = preprocessing_set[\"date\"].map(get_nsm).apply(pd.Series)\n",
    "time_test[[\"NSM_sin\", \"NSM_cos\"]] = preprocessing_set[\"date\"].map(get_cyclic_nsm).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NSM</th>\n",
       "      <th>NSM_sin</th>\n",
       "      <th>NSM_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11928</th>\n",
       "      <td>46800</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11089</th>\n",
       "      <td>61800</td>\n",
       "      <td>-0.976296</td>\n",
       "      <td>-0.216440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8623</th>\n",
       "      <td>51000</td>\n",
       "      <td>-0.537300</td>\n",
       "      <td>-0.843391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15433</th>\n",
       "      <td>76200</td>\n",
       "      <td>-0.675590</td>\n",
       "      <td>0.737277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11827</th>\n",
       "      <td>72600</td>\n",
       "      <td>-0.843391</td>\n",
       "      <td>0.537300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NSM   NSM_sin   NSM_cos\n",
       "11928  46800 -0.258819 -0.965926\n",
       "11089  61800 -0.976296 -0.216440\n",
       "8623   51000 -0.537300 -0.843391\n",
       "15433  76200 -0.675590  0.737277\n",
       "11827  72600 -0.843391  0.537300"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_test[[\"NSM\", \"NSM_sin\", \"NSM_cos\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical day of the week\n",
    "As NSM does not convey any information about the day of the week, we can also convert the date into categorical values for each day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_day(timestamp):\n",
    "    dt = parse_timestamp(timestamp)\n",
    "    day_num = dt.weekday()\n",
    "\n",
    "    # Categories in order: Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday\n",
    "    categories = [0,0,0,0,0,0,0]\n",
    "    categories[day_num] = 1\n",
    "    \n",
    "    return tuple(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_of_week = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "time_test[days_of_week] = preprocessing_set[\"date\"].map(get_categorical_day).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11928</th>\n",
       "      <td>2016-04-03 13:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11089</th>\n",
       "      <td>2016-03-28 17:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8623</th>\n",
       "      <td>2016-03-11 14:10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15433</th>\n",
       "      <td>2016-04-27 21:10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11827</th>\n",
       "      <td>2016-04-02 20:10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date  Monday  Tuesday  Wednesday  Thursday  Friday  \\\n",
       "11928  2016-04-03 13:00:00       0        0          0         0       0   \n",
       "11089  2016-03-28 17:10:00       1        0          0         0       0   \n",
       "8623   2016-03-11 14:10:00       0        0          0         0       1   \n",
       "15433  2016-04-27 21:10:00       0        0          1         0       0   \n",
       "11827  2016-04-02 20:10:00       0        0          0         0       0   \n",
       "\n",
       "       Saturday  Sunday  \n",
       "11928         0       1  \n",
       "11089         0       0  \n",
       "8623          0       0  \n",
       "15433         0       0  \n",
       "11827         1       0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_test[[\"date\"] + days_of_week].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of different timestamp metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Appliances    1.000000\n",
       "NSM_sin       0.259581\n",
       "hour_sin      0.235093\n",
       "hour_cos      0.233518\n",
       "NSM           0.215358\n",
       "hour_num      0.215016\n",
       "NSM_cos       0.205434\n",
       "day_sin       0.054228\n",
       "Monday        0.052503\n",
       "Tuesday       0.043997\n",
       "Saturday      0.032062\n",
       "Wednesday     0.030169\n",
       "Friday        0.026120\n",
       "Thursday      0.024768\n",
       "Sunday        0.010392\n",
       "day_cos       0.008363\n",
       "day_num       0.003635\n",
       "Name: Appliances, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_correlation = time_test.corr()\n",
    "time_correlation[\"Appliances\"].map(abs).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot histograms for all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = preprocessing_set.hist(bins=100,figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#scaling = Pipeline([\n",
    "#    (\"scaler\", StandardScaler())\n",
    "#])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_set[[\"NSM_sin\", \"NSM_cos\"]] = preprocessing_set[\"date\"].map(get_cyclic_nsm).apply(pd.Series)\n",
    "preprocessing_set[[\"hour_sin\", \"hour_cos\", \"day_sin\", \"day_cos\"]] = preprocessing_set[\"date\"].map(get_cyclic_time).apply(pd.Series)\n",
    "preprocessing_set[[\"hour_num\", \"day_num\"]] = preprocessing_set[\"date\"].map(get_numeric_time).apply(pd.Series)\n",
    "preprocessing_set[days_of_week] = preprocessing_set[\"date\"].map(get_categorical_day).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise feature correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = preprocessing_set.corr().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation code adapted from https://seaborn.pydata.org/examples/many_pairwise_correlations.html\n",
    "import seaborn as sns\n",
    "\n",
    "# Mask upper half as it is just the mirror of the lower half\n",
    "mask = np.zeros_like(correlation, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Colormap\n",
    "cmap = sns.diverging_palette(220,10,as_cmap=True)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(correlation, mask=mask, cmap=cmap, center=0, square=True, linewidths=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correlation[\"Appliances\"].map(abs).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "sel = VarianceThreshold(threshold=(.8* (1-.8)))\n",
    "#sel.fit_transform(energy_train.drop(\"date\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = preprocessing_set.drop(\"date\", axis=1)\n",
    "sel.fit_transform(t)\n",
    "labels= [t.columns[x] for x in sel.get_support(indices=True) if x]\n",
    "df = pd.DataFrame(sel.fit_transform(t), columns=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VarianceThreshold_selector(data):\n",
    "\n",
    "    #Select Model\n",
    "    selector = VarianceThreshold(0.2) #Defaults to 0.0, e.g. only remove features with the same value in all samples\n",
    "\n",
    "    #Fit the Model\n",
    "    selector.fit(data)\n",
    "    features = selector.get_support(indices = True) #returns an array of integers corresponding to nonremoved features\n",
    "    features = [column for column in data[features]] #Array of all nonremoved features' names\n",
    "\n",
    "    #Format and Return\n",
    "    selector = pd.DataFrame(selector.transform(data))\n",
    "    selector.columns = features\n",
    "    return selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VarianceThreshold_selector(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_forward_selection(model):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = energy.corr()\n",
    "cm[\"Appliances\"].map(abs).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines\n",
    "All the done above can be converted into pipelines. This allows us to modularly choose the exact stages to go through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaner(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self # No fitting for cleaning step\n",
    "        \n",
    "    def transform(self, X):\n",
    "        # Temperature columns\n",
    "        Tcols= [\"T1\", \"T2\", \"T3\", \"T4\", \"T5\", \"T6\", \"T7\", \"T8\", \"T9\", \"T_out\", \"Tdewpoint\"]\n",
    "        \n",
    "        # Humidity columns\n",
    "        RHcols = [\"RH_1\", \"RH_2\", \"RH_3\", \"RH_4\", \"RH_5\", \"RH_6\", \"RH_7\", \"RH_8\", \"RH_9\", \"RH_out\"]\n",
    "        \n",
    "        # Non negative columns\n",
    "        Ncols = [\"lights\", \"Windspeed\", \"Visibility\", \"Press_mm_hg\"]\n",
    "        \n",
    "        X = self.clean_data(-50,50,Tcols,X) # Clean temperatures\n",
    "        X = self.clean_data(0,100,RHcols,X) # Clean humidity\n",
    "        X = self.clean_data(0,1100,Ncols,X) # Clean non negative values, 1080 was the maximum value of any data cell from peeking at data with DataFrame.describe()\n",
    "        \n",
    "        return X\n",
    "    \n",
    "\n",
    "    def clean_data(self, min_value, max_value, columns, data):\n",
    "        clean_data = data.copy()\n",
    "        for col in columns:\n",
    "            clean_data = clean_data[ (clean_data[col] <= max_value)\n",
    "                                   & (clean_data[col] >= min_value)]\n",
    "        return clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datetime transformation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This transformer takes the DataFrame and converts the date timestamp\n",
    "# The date column is then dropped\n",
    "class DatetimeTransformer(BaseEstimator, TransformerMixin):\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self # No fitting in transformer\n",
    "    \n",
    "    def transform(self, X):\n",
    "        cyclic_columns = [\"hour_sin\", \"hour_cos\", \"day_sin\", \"day_cos\"]    \n",
    "        X[cyclic_columns] = self.mapTransformation(X, get_cyclic_time)\n",
    "        X.drop([\"day_sin\", \"day_cos\"], axis=1)\n",
    "        \n",
    "        categorical_columns = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"] \n",
    "        X[categorical_columns] = self.mapTransformation(X, get_categorical_day)\n",
    "        \n",
    "        return self.dropDate(X)\n",
    "        \n",
    "    def mapTransformation(self, X, mapper):\n",
    "        return X[\"date\"].map(mapper).apply(pd.Series)\n",
    "    \n",
    "    def dropDate(self, X):\n",
    "        return X.drop(\"date\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DFNPConverter` converts between a DataFrame and numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFNPConverter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, toDF=True, DF_index=None, DF_columns=None):\n",
    "        self.toDF = toDF\n",
    "        \n",
    "        # If converting back to DF, need index and columns of original DataFrame\n",
    "        self.DF_index = DF_index\n",
    "        self.DF_columns = DF_columns\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self # No fitting for df/np conversion\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.toDF:\n",
    "            return pd.DataFrame(X, index=self.DF_index, columns=self.DF_columns)\n",
    "        \n",
    "        else:\n",
    "            return X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    (\"cleaning\", DataCleaner()),\n",
    "    (\"time_conversion\", DatetimeTransformer()),\n",
    "    (\"feature_scaling\", StandardScaler())\n",
    "])\n",
    "\n",
    "linreg_pipeline = Pipeline([\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "polyreg_pipeline = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(degree=2)),\n",
    "    (\"model\", LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, preprocess, model, input, output, kfold=5):\n",
    "        self.model = model\n",
    "        self.preprocess = preprocess\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "        self.kfold = kfold\n",
    "        \n",
    "    \n",
    "    def train(self, params=False):\n",
    "        processed_input = self.preprocess.fit_transform(self.input)\n",
    "        \n",
    "        if not params:\n",
    "            self.model.fit(processed_input, self.output)\n",
    "            return self.cross_validate(processed_input, self.model)\n",
    "        else:\n",
    "            self.model.fit(processed_input, self.output)\n",
    "            best_model = self.get_model().best_estimator_\n",
    "            return self.cross_validate(processed_input, model=best_model)\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model.named_steps[\"model\"]\n",
    "        \n",
    "    def cross_validate(self, processed_input, model):\n",
    "        prediction = cross_val_predict(model, processed_input, self.output, cv=self.kfold)\n",
    "        rmse = np.sqrt(mean_squared_error(self.output, prediction))\n",
    "        r2 = r2_score(self.output, prediction)\n",
    "        \n",
    "        return rmse,r2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "# Drop output column and random variables column\n",
    "input = energy_train.drop([\"Appliances\", \"rv1\", \"rv2\"], axis=1)\n",
    "output = energy_train[\"Appliances\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_trainer = Trainer(preprocessing_pipeline, linreg_pipeline, input, output, kfold=5)\n",
    "lin_rmse, lin_r2 = lin_trainer.train()\n",
    "lin_model = lin_trainer.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ridge_pipeline = Pipeline([\n",
    "    (\"model\", GridSearchCV(Ridge(), [{\"alpha\": [0.1,0.5,1,2,5,10,20]}]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_trainer = Trainer(preprocessing_pipeline, ridge_pipeline, input, output, kfold=5)\n",
    "ridge_rmse, ridge_r2 = ridge_trainer.train(params=True)\n",
    "ridge_model = ridge_trainer.get_model().best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_trainer.get_model().best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_trainer = Trainer(preprocessing_pipeline, polyreg_pipeline, input, output, kfold=5)\n",
    "poly_rmse, poly_r2 = poly_trainer.train()\n",
    "poly_model = poly_trainer.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyridge_pipeline = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(degree=2)),\n",
    "    (\"model\", Ridge(alpha=10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyridge_trainer = Trainer(preprocessing_pipeline, polyridge_pipeline, input, output, kfold=5)\n",
    "polyridge_rmse, polyridge_r2 = polyridge_trainer.train()\n",
    "polyridge_model = ridge_trainer.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyridge_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyridge_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use log\n",
    "# https://datascience.stackexchange.com/questions/5000/proper-way-of-fighting-negative-outputs-of-a-regression-algorithms-where-output\n",
    "# l = list(map(np.exp, ridge_res))\n",
    "# output.map(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(l, output, alpha=0.1)\n",
    "plt.xlabel(\"Predicted value\")\n",
    "plt.ylabel(\"True value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = list(map(np.exp, lasso_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(l, output, alpha=0.1)\n",
    "plt.xlabel(\"Predicted value\")\n",
    "plt.ylabel(\"True value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
